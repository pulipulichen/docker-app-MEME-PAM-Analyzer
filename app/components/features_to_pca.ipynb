{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa64e993-1d09-45fa-9d64-49beea785ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def features_to_pca(db_name):\n",
    "    \n",
    "    # Find the first occurrence of \"-\" in the text\n",
    "    index_of_dash = db_name.find(\"-\")\n",
    "\n",
    "    if index_of_dash != -1:\n",
    "        result = db_name[index_of_dash + 1:]\n",
    "    else:\n",
    "        result = \"\"\n",
    "        \n",
    "    prefix_name = \"visual_pca-\"\n",
    "    if db_name.startswith(\"semantic_representation-\"):\n",
    "        prefix_name = \"semantic_pca-\"\n",
    "\n",
    "    output_db_name = prefix_name + result\n",
    "    \n",
    "    # print(output_db_name)\n",
    "    # return \n",
    "    \n",
    "    if os.path.isfile(f\"{DATA_PATH}/{output_db_name}\"):\n",
    "        return\n",
    "    \n",
    "    # ================\n",
    "    \n",
    "    image_list, features2DArray = get_features_2d_array(db_name)\n",
    "    \n",
    "    # ================\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    try:\n",
    "        pca.fit(features2DArray)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: \" + db_name)\n",
    "        print(len(features2DArray))\n",
    "        print(features2DArray[0])\n",
    "        raise e\n",
    "    \n",
    "    pca_features=pca.transform(features2DArray)\n",
    "    # print(pca_features)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(pca_features)\n",
    "    # print(normalized_data)\n",
    "    \n",
    "    # ================\n",
    "    \n",
    "    PCA_DB = db_pca(output_db_name)\n",
    "    \n",
    "    for index, image_path in enumerate(image_list):\n",
    "        # image_path = row[\"image\"]\n",
    "        \n",
    "        x = normalized_data[index][0]\n",
    "        y = normalized_data[index][1]\n",
    "        \n",
    "        PCA_DB(image=image_path, x=x, y=y).save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bec20c-e9d3-4b02-a1ea-3bc85c88d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_feature_to_pca():\n",
    "#     for item in MODEL_LIST_VISUAL_LIST:\n",
    "\n",
    "#         model_name = item[\"model_name\"]\n",
    "#         model_config = item[\"model_config\"]\n",
    "#         layer = item[\"layer\"]\n",
    "        \n",
    "#         db_path = f\"{DATA_PATH}/visual_representation-{model_name}_{layer}.db\"\n",
    "        \n",
    "#         db_name = os.path.basename(db_path)\n",
    "#         features_to_pca(db_name)\n",
    "#         # print(db_path)\n",
    "#         # raise ValueError(\"This is a custom error message.\")\n",
    "    \n",
    "# #     for db_path in glob.glob(f\"{DATA_PATH}/*_representation-*.db\"):\n",
    "        \n",
    "# #         db_name = os.path.basename(db_path)\n",
    "        \n",
    "# #         features_to_pca(db_name)\n",
    "\n",
    "#     for model_name in MODEL_LIST_SEMANTIC_LIST:\n",
    "\n",
    "#         db_path = f\"{DATA_PATH}/semantic_representation-{model_name}.db\"\n",
    "        \n",
    "#         # print(db_path)\n",
    "#         db_name = os.path.basename(db_path)\n",
    "#         features_to_pca(db_name)\n",
    "    for db_path in build_db_path_list('representation'):\n",
    "        db_name = os.path.basename(db_path)\n",
    "        features_to_pca(db_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa80c79-10f8-4c27-8535-17059805a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_db_path_list(phase):\n",
    "    output = []\n",
    "    for item in MODEL_LIST_VISUAL_LIST:\n",
    "\n",
    "        model_name = item[\"model_name\"]\n",
    "        model_config = item[\"model_config\"]\n",
    "        layer = item[\"layer\"]\n",
    "        \n",
    "        db_path = f\"{DATA_PATH}/visual_{phase}-{model_name}_{layer}.db\"\n",
    "        output.append(db_path)\n",
    "        # print(db_path)\n",
    "        # raise ValueError(\"This is a custom error message.\")\n",
    "    \n",
    "#     for db_path in glob.glob(f\"{DATA_PATH}/*_representation-*.db\"):\n",
    "        \n",
    "#         db_name = os.path.basename(db_path)\n",
    "        \n",
    "#         features_to_pca(db_name)\n",
    "\n",
    "    for model_name in MODEL_LIST_SEMANTIC_LIST:\n",
    "\n",
    "        db_path = f\"{DATA_PATH}/semantic_{phase}-{model_name}.db\"\n",
    "        output.append(db_path)\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
