{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
=======
   "execution_count": 11,
>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
   "id": "6ac6f0cd-2ab0-4fe4-8937-20bab88267c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "81d26bacb35145a4aff7d42593ffdfaa",
=======
       "model_id": "f4e40385b7db4facac40528b907f6a86",
>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Start Analyzing</b><br />(If you have completed setting up the form below, pleas…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "1be0b025e1a444ecb51301074bf91b30",
=======
       "model_id": "cbcba3887595426588e5aef871c0df6b",
>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Data Path</b> (\"./input/data/\")'), Text(value='./input/data_formal_20240530-1342…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "8e3514f62d5348d0b4afc05e642adaa2",
=======
       "model_id": "a4f96f7ca1b748ba8b51e15b26537f54",
>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Calculate F1 Score</b> (set True for running an experiment)'), Dropdown(index=1,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "69429f920dda42e197bfb670d8baae14",
=======
       "model_id": "4b07a2a62c304dc5a9d4da294e5a8223",
>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Max K</b><br />(\"auto\" or a number from 2. If \"Calculate F1 Score\" is True, Max …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "7fa9ab4f47d2425e9652ab7a3485020d",
=======
       "model_id": "4004f2c1403a4105b26a4ea4aaec1fa1",

>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Min K</b>'), Text(value='3', layout=Layout(width='90%'), placeholder='2')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "26a47c35df2840e0bf96f6a82038b561",
=======
       "model_id": "608d368fec3047fe8e03346fefb8f251",

>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Visual Representation Models</b>'), Textarea(value='[{\\n            \"model_name\"…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609d7274c40e47af842483fb8bcbb060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Semantic Representation Models</b>'), Textarea(value=\"['all-MiniLM-L12-v2']\", la…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_K is 20\n"
     ]
    }
   ],
   "source": [
    "%run ./components/index.ipynb"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 48,
=======
   "execution_count": 12,
>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
   "id": "d34fff11-6054-4434-bd5c-13df440323ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
<<<<<<< HEAD
      "Start time: 2024-06-01 17:27:35.281418\n",
      "========================================================\n",
      "Start to cluster: visual_representation-ConvNeXtLarge_convnext_large_head_layernorm.db\n",
      "Start to cluster: semantic_representation-all-MiniLM-L12-v2.db\n",
      "{'visual_cluster-ConvNeXtLarge_convnext_large_head_layernorm.db': 9, 'semantic_cluster-all-MiniLM-L12-v2.db': 6}\n",
      "./input/data_formal_20240530-1342/visual_cluster-ConvNeXtLarge_convnext_large_head_layernorm.db\n",
      "visual_cluster-ConvNeXtLarge_convnext_large_head_layernorm.db\n",
      "./input/data_formal_20240530-1342/semantic_cluster-all-MiniLM-L12-v2.db\n",
      "semantic_cluster-all-MiniLM-L12-v2.db\n",
      "========================================================\n",
      "End time: 2024-06-01 17:29:18.376550\n",
      "Script execution time: 1.72 minutes\n",
=======
      "Start time: 2024-03-12 19:36:21.261866\n",
      "========================================================\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f30fe6d3640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f30fe6d3f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/data/semantic_cluster-all-MiniLM-L12-v2.db\n",
      "./input/data/semantic_cluster-all-MiniLM-L6-v2.db\n",
      "./input/data/semantic_cluster-distilroberta-base-paraphrase-v1.db\n",
      "./input/data/semantic_cluster-paraphrase-multilingual-mpnet-base-v2.db\n",
      "./input/data/visual_cluster-ConvNeXtLarge_convnext_large_head_gap.db\n",
      "./input/data/visual_cluster-ConvNeXtLarge_convnext_large_head_layernorm.db\n",
      "./input/data/visual_cluster-ConvNeXtXLarge_convnext_xlarge_head_gap.db\n",
      "./input/data/visual_cluster-ConvNeXtXLarge_convnext_xlarge_head_layernorm.db\n",
      "./input/data/visual_cluster-EfficientNetV2B0_avg_pool.db\n",
      "./input/data/visual_cluster-EfficientNetV2B0_top_activation.db\n",
      "./input/data/visual_cluster-VGG16_fc1.db\n",
      "./input/data/visual_cluster-VGG16_fc2.db\n",
      "./input/data/visual_cluster-VGG19_fc1.db\n",
      "./input/data/visual_cluster-VGG19_fc2.db\n",
      "========================================================\n",
      "End time: 2024-03-12 19:40:18.565753\n",
      "Script execution time: 3.96 minutes\n",
>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "if START_ANALYZING is True:\n",
    "    start_time = time.time()\n",
    "    print(\"========================================================\")\n",
    "    print(\"Start time:\", datetime.datetime.now())\n",
    "    print(\"========================================================\")\n",
    "    \n",
    "    extract_representation()\n",
    "    db_feature_to_pca()\n",
    "    cluster_number_dict = db_feature_to_cluster()\n",
    "    all_merge_pca_cluster(cluster_number_dict)\n",
    "    \n",
    "    if CALC_F1_SCORE is True:\n",
    "        db_clusters_to_f1scores()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time_minutes = (end_time - start_time) / 60\n",
    "    print(\"========================================================\")\n",
    "    print(\"End time:\", datetime.datetime.now())\n",
    "    print(\"Script execution time: {:.2f} minutes\".format(elapsed_time_minutes))\n",
    "    print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "7d4ccffb-17f1-4b89-ba4c-ce700a33090b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ead94-d5d9-4974-9d3a-6cb8456d8cc5",
=======
   "id": "6338b990-34d1-4cfe-bb03-b6ba1cfc1ac2",
>>>>>>> 1e3bcd092fb34c6d2847a16be79f5421fe4a104e
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
